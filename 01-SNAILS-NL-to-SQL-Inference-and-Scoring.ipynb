{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End NL-to-SQL Inference and Evaluation\n",
    "The intent of this notebook is to demonstrate the end-to-end process for reproducing the data collection, synthesis, evaluation, and consolidation required to formulate a dataset on which to run statistical experiments evaluating the relationship between schema identifier naturalness and NL-to-SQL model performance.\n",
    "\n",
    "This notebook is one of two notebooks created for this purpose. The second notebook is end-to-end-prototype-analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 Kyle Luoma\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/SNAILS/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from src import end_to_end_data_prep_and_prediction as pred\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database and model selections\n",
    "Comment or uncomment the databases and models in the dictionaries prior to running the main function in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_spider_databases = [(\"spider\", db) for db in [\n",
    "        'battle_death',\n",
    "        'car_1',\n",
    "        'concert_singer',\n",
    "        'course_teach',\n",
    "        'cre_Doc_Template_Mgt',\n",
    "        'dog_kennels',\n",
    "        'employee_hire_evaluation',\n",
    "        'flight_2',\n",
    "        'museum_visit',\n",
    "        'network_1',\n",
    "        'orchestra',\n",
    "        'pets_1',\n",
    "        'poker_player',\n",
    "        'real_estate_properties',\n",
    "        'singer',\n",
    "        'student_transcripts_tracking',\n",
    "        'tvshow',\n",
    "        'voter_1',\n",
    "        'world_1',\n",
    "        'wta_1'\n",
    "        ]]\n",
    "\n",
    "selected_snails_databases = [(\"snails\", db) for db in [\n",
    "        \"ASIS_20161108_HerpInv_Database\",\n",
    "        \"ATBI\",\n",
    "        \"CratersWildlifeObservations\",\n",
    "        \"KlamathInvasiveSpecies\",\n",
    "        \"NorthernPlainsFireManagement\",\n",
    "        \"NTSB\",\n",
    "        \"NYSED_SRC2022\",\n",
    "        \"PacificIslandLandbirds\",\n",
    "        \"SBODemoUS-Banking\",\n",
    "        \"SBODemoUS-Business Partners\",\n",
    "        \"SBODemoUS-Finance\",\n",
    "        \"SBODemoUS-General\",\n",
    "        \"SBODemoUS-Human Resources\",\n",
    "        \"SBODemoUS-Inventory and Production\",\n",
    "        \"SBODemoUS-Reports\",\n",
    "        \"SBODemoUS-Sales Opportunities\",\n",
    "        \"SBODemoUS-Service\"\n",
    "        ]]\n",
    "\n",
    "selected_models = [\n",
    "        \"gpt-4o\", \n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"DINSQL\",\n",
    "        \"CodeS\",\n",
    "        # \"Phind-CodeLlama-34B-v2\" #Use only with bypass_nl_sql_inference=True in main call below\n",
    "        ]\n",
    "\n",
    "selected_naturalness = [\n",
    "        \"NATIVE\", \n",
    "        \"N1\", \n",
    "        \"N2\", \n",
    "        \"N3\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Main function in pred\n",
    "\n",
    "Running this as main with the above combinations of benchmark, database, model, and naturalness level\n",
    "    reproduces the NL-to-SQL annotations used in our analysis.\n",
    "    NOTE: Unfortunately, the Phind-CodeLlama model cited in our paper is no longer available on TogetherAI,\n",
    "    so we cannot offer a simple reproducibility solution here. SQL inference output from this model is\n",
    "    available in the ./queries/predicted directory.\n",
    "\n",
    "##### Outputs\n",
    "- Queries predicted by LLMs are stored in: ./db/queries/predicted \n",
    "- Excel files containing the analysis results are stored in: ./data/nl-to-sql_performance_annotations/pending_evaluation\n",
    "- Individual query generation logs can be found in ./logs\n",
    "\n",
    "##### Next Steps\n",
    "Once NL-to-SQL inference and follow-on evaluations are complete, run \n",
    "```python\n",
    "python ./src/query_manual_evaluation.py\n",
    "```\n",
    "to perform manual evaluation of the results files.\n",
    "Load the files from the /pending_evaluation folder and once you have manually scored the results, save them to ./data/nl-to-sql_performance_annotations\n",
    "\n",
    "After manual validation, you can generate the results analysis as they appear in our report using the `reproducibility-SNAILS-NL-to-SQL-naturalness-analysis.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data Loading ###\n",
      "### SQL Inference ###\n",
      "### Determine Schema and Query Naturalness ###\n",
      "### Generate gold query statistics and naturalness scores ###\n",
      "### Make a list of all aliases in all queries ###\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'java -jar ./bin/SQLParserQueryAnalyzer_jar/SQLParserQueryAnalyzer.jar --schematagger \"SELECT COUNT(*) TURTLECOUNT  FROM TBLFIELDDATATURTLEMEASUREMENTS WHERE AGE = \\'5\\' \" \"tsql\" --dialect tsql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/kyle/miniconda3/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/home/kyle/miniconda3/lib/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/home/kyle/SNAILS/src/query_profiler.py\", line 198, in tag_query\n    response = subprocess.run(\n               ^^^^^^^^^^^^^^^\n  File \"/home/kyle/miniconda3/lib/python3.12/subprocess.py\", line 548, in run\n    with Popen(*popenargs, **kwargs) as process:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kyle/miniconda3/lib/python3.12/subprocess.py\", line 1026, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/home/kyle/miniconda3/lib/python3.12/subprocess.py\", line 1955, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'java -jar ./bin/SQLParserQueryAnalyzer_jar/SQLParserQueryAnalyzer.jar --schematagger \"SELECT COUNT(*) TURTLECOUNT  FROM TBLFIELDDATATURTLEMEASUREMENTS WHERE AGE = \\'5\\' \" \"tsql\" --dialect tsql'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# selected_spider_databases +\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     selected_snails_databases,\n\u001b[1;32m      4\u001b[0m     selected_models,\n\u001b[1;32m      5\u001b[0m     selected_naturalness\n\u001b[1;32m      6\u001b[0m ):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnaturalness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbypass_nl_sql_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# set to True if you don't want to run LLM NL-to-SQL and only want to run the additional evaluation steps\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_list_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspider\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.local/spider_dbinfo.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msnails\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.local/dbinfo.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcombo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SNAILS/src/end_to_end_data_prep_and_prediction.py:279\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model, service, naturalness, database, bypass_nl_sql_inference, db_list_file)\u001b[0m\n\u001b[1;32m    276\u001b[0m profiler \u001b[38;5;241m=\u001b[39m qpr\u001b[38;5;241m.\u001b[39mQueryProfiler()\n\u001b[1;32m    277\u001b[0m alias_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 279\u001b[0m mp_tag_df_gold_list \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_nl_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_gold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tag_df \u001b[38;5;129;01min\u001b[39;00m mp_tag_df_gold_list:\n\u001b[1;32m    284\u001b[0m     alias_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tag_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_aliases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'java -jar ./bin/SQLParserQueryAnalyzer_jar/SQLParserQueryAnalyzer.jar --schematagger \"SELECT COUNT(*) TURTLECOUNT  FROM TBLFIELDDATATURTLEMEASUREMENTS WHERE AGE = \\'5\\' \" \"tsql\" --dialect tsql'"
     ]
    }
   ],
   "source": [
    "for combo in product(\n",
    "    # selected_spider_databases +\n",
    "    selected_snails_databases,\n",
    "    selected_models,\n",
    "    selected_naturalness\n",
    "):\n",
    "    pred.main(\n",
    "        model=combo[1],\n",
    "        service=\"openai\",\n",
    "        naturalness=combo[2],\n",
    "        database=combo[0][1],\n",
    "        bypass_nl_sql_inference=True, # set to True if you don't want to run LLM NL-to-SQL and only want to run the additional evaluation steps\n",
    "        db_list_file={\n",
    "            \"spider\": \".local/spider_dbinfo.json\",\n",
    "            \"snails\": \".local/dbinfo.json\"\n",
    "            }[combo[0][0]]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
